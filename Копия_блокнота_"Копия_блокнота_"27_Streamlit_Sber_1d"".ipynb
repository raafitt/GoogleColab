{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raafitt/RNN/blob/LSTM/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%2227_Streamlit_Sber_1d%22%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VNPaaVxF1lc1",
        "outputId": "b1858464-985d-41c3-fdd8-d7869e266ac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: schedule in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.42.0)\n",
            "Requirement already satisfied: altair in /usr/local/lib/python3.11/dist-packages (5.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair) (1.26.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair) (0.22.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests schedule nest_asyncio streamlit altair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tsOF_VIMAPBv",
        "outputId": "b7a5e03c-555e-4dd8-efe9-3a38ddc340a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJMwWBATIi4A"
      },
      "source": [
        "# Файл где создается и обучается модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMtKxDSHXI2B",
        "outputId": "91dcf7ac-a403-4b46-c031-76c14128ff84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model.py\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint,Callback\n",
        "import streamlit as st\n",
        "\n",
        "def create_model(input):\n",
        "  n_features=1\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(50, activation='relu', input_shape=input))\n",
        "  model.add(Dense(10, activation='relu'))\n",
        "  model.add(Dense(n_features))\n",
        "\n",
        "  callbacks=ModelCheckpoint('best_model_1min.keras', mode='min',monitor='val_loss', save_best_only=True,verbose=True)\n",
        "\n",
        "  class StreamlitCallback(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "      st.write(f\"Epoch {epoch+1}: loss = {logs['loss']}, val_loss = {logs['val_loss']}\")\n",
        "\n",
        "  model.compile(optimizer='adam', loss='mse')\n",
        "  return model,callbacks,StreamlitCallback\n",
        "\n",
        "def fit_model(model,train,val,callbacks):\n",
        "  return model.fit(train, validation_data=val, epochs=5,callbacks=callbacks).history\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP0ETz9YTc71"
      },
      "source": [
        "Вспомогательный файл, возвращающий прогноз"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBlFJwcG_6MO",
        "outputId": "09ca1d3a-2dd1-4db1-b55b-deae0de0af3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing lstm_model.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile lstm_model.py\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "\n",
        "model=tf.keras.models.load_model('/content/drive/MyDrive/27 streamlit/best_model_1d(2).keras')\n",
        "# Загрузка scaler\n",
        "with open('/content/drive/MyDrive/27 streamlit/scaler_1d.pkl', 'rb') as f:\n",
        "  scaler = pickle.load(f)\n",
        "\n",
        "\n",
        "# Функция расчета результата предсказания\n",
        "def get_pred(x_test):\n",
        "    n_input = 2\n",
        "    x_test = np.reshape(x_test, (-1, n_input))\n",
        "    x_test = np.reshape(x_test, (len(x_test) * n_input, 1))\n",
        "    batch = len(x_test) // n_input\n",
        "    x_test = scaler.transform(x_test)\n",
        "    x_test = np.reshape(x_test, (batch, n_input, 1))\n",
        "    # Вычисление и денормализация предсказания\n",
        "    y_pred_unscaled = scaler.inverse_transform(model.predict(x_test, verbose=0))\n",
        "    return np.round(y_pred_unscaled[0][0],2)\n",
        "\n",
        "if __name__ == \"__get_pred__\":\n",
        "    get_pred()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiyBuPMtIu4X"
      },
      "source": [
        "# Файл с приложением (загрузка обучающих данных, обучение модели, демонстрация работы)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibgSxmH2yWM8",
        "outputId": "35aef59e-4a09-45f5-9e6d-474f8701c2b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile main.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import io\n",
        "import pandas as pd\n",
        "from collections import deque\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from io import StringIO\n",
        "from model import create_model,fit_model\n",
        "import altair as alt\n",
        "import aiohttp\n",
        "import asyncio\n",
        "import json\n",
        "import nest_asyncio\n",
        "from lstm_model import get_pred\n",
        "\n",
        "\n",
        "\n",
        "st.title('Загрузка данных, обучение и инференс модели')\n",
        "uploaded_file = st.file_uploader(\"Загрузите датасет в формате csv\")\n",
        "if uploaded_file is not None:\n",
        "    price = pd.read_csv(uploaded_file,sep=';', index_col='time', usecols = ['time','c'], parse_dates=['time'])\n",
        "    price.dropna(inplace=True)\n",
        "    price.replace({',':'.'},regex=True,inplace=True)\n",
        "    price = price.sort_index()\n",
        "    st.write(price.head())\n",
        "\n",
        "    train_data = price[:'2024-09-30']\n",
        "    test_data = price['2024-09-30':]\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    scaler.fit(train_data)\n",
        "    scaled_train_data = scaler.transform(train_data)\n",
        "    scaled_test_data = scaler.transform(test_data)\n",
        "\n",
        "    n_input = 2  # Размерность входных данных\n",
        "    n_features = 1 # Размерность выходных данных\n",
        "    BATCH_SIZE = 1 # Размер пакета\n",
        "\n",
        "    generator = TimeseriesGenerator(scaled_train_data, scaled_train_data, length=n_input, batch_size=BATCH_SIZE)\n",
        "    st.write(f'Форма обучающего пакета: {generator[0][0].shape}, y: {generator[0][1].shape}')\n",
        "\n",
        "    validator = TimeseriesGenerator(scaled_test_data, scaled_test_data, length=n_input, batch_size=BATCH_SIZE)\n",
        "    st.write(f'Форма валидационного пакета: {validator[0][0].shape}, y: {validator[0][1].shape}')\n",
        "\n",
        "    tester = TimeseriesGenerator(scaled_test_data, scaled_test_data, length=n_input, batch_size=scaled_test_data.shape[0])\n",
        "    x_test, y_test = tester[0]\n",
        "    st.write(f'Форма тестовой выборки: {x_test.shape}, y: {y_test.shape}')\n",
        "\n",
        "    model,callb1,callb2=create_model(generator[0][0].shape[1:])\n",
        "    if st.button('Показать архитектуру модели'):\n",
        "      st.write('Архитектура модели')\n",
        "      # Перенаправление вывода summary в строку\n",
        "      summary_str = io.StringIO()\n",
        "      model.summary(print_fn=lambda x: summary_str.write(x + '\\n'))\n",
        "      st.text(summary_str.getvalue())\n",
        "\n",
        "    st.empty()\n",
        "    if st.button('Начать обучение'):\n",
        "      st.write('Начало обучения...')\n",
        "      st.write(fit_model(model,generator,validator,[callb1,callb2()]))\n",
        "      st.write('Обучение завершено.')\n",
        "\n",
        "    #Демонстрация работы модели(предсказыване цен на акции сбера в реальном времени)\n",
        "    st.empty()\n",
        "    if st.button('Запустить прогноз цен акций Сбера'):\n",
        "      nest_asyncio.apply()\n",
        "      #limit = n_input\n",
        "      #interval = '1min'\n",
        "\n",
        "      url='https://api-invest-gw.tinkoff.ru/market-data-history/api/public/v1/candles?instrument_id=e6123145-9665-43e0-8413-cd61b8aa9b13&limit=600&interval=1min&appName=invest_terminal&appVersion=2.0.0&sessionId=TCPiOzihJNgYQgKmUaO0y3hIqOiBdDCF.ds-prod-api-119'\n",
        "      #Функцмя извлечения цены закрытия\n",
        "      def get_close(candles):\n",
        "          closes = []\n",
        "          for elem in candles:\n",
        "              closes.append(elem['c'])\n",
        "          return closes\n",
        "\n",
        "      #Асинхронная Функция получения котировок\n",
        "      async def fetch_quotes(session, url):\n",
        "          async with session.get(url) as response:\n",
        "              return await response.json()\n",
        "\n",
        "      async def get_quotes_periodically(url, interval):\n",
        "          async with aiohttp.ClientSession() as session:\n",
        "              #Для ограничения точек на графике используется очередь\n",
        "              data = deque(maxlen=7)\n",
        "              chart1 = st.empty()\n",
        "              chart2 = st.empty()\n",
        "              # Основной цикл с периодическим обновлением данных\n",
        "              while True:\n",
        "                  try:\n",
        "                      quotes = await fetch_quotes(session, url)\n",
        "                      candles = quotes['payload']['candles']\n",
        "                      closes = get_close(list(candles))\n",
        "\n",
        "                      # Получение предсказания\n",
        "                      pred_value = np.round(get_pred(closes), 2)\n",
        "\n",
        "                      # Извлекаем минуты и секунды\n",
        "                      time = pd.Timestamp.now()\n",
        "                      # Добавляем 60 секунд к текущему времени\n",
        "                      next_time = time + pd.Timedelta(seconds=60)\n",
        "\n",
        "                      data.append({'next_time': next_time,'time': time, 'pred_price': pred_value, 'price': closes[1]})\n",
        "                      # Создаем DataFrame для графика\n",
        "                      df = pd.DataFrame(data)\n",
        "\n",
        "                      y_min_pred = df['pred_price'].min()-df['pred_price'].min()*0.0001\n",
        "                      y_max_pred = df['pred_price'].max()+df['pred_price'].max()*0.0001\n",
        "                      y_min = df['price'].min()-df['price'].min()*0.0001\n",
        "                      y_max = df['price'].max()+df['price'].max()*0.0001\n",
        "\n",
        "                      # Построение двух линий: одна для реальных цен, другая для предсказанных\n",
        "                      price_line = alt.Chart(df).mark_line(color='blue').encode(\n",
        "                            x=alt.X('time:T', axis=alt.Axis(format='%M', title='Минуты')),\n",
        "                            y=alt.Y('price:Q', scale=alt.Scale(domain=[y_min, y_max]))\n",
        "                      ).properties(title='График изменения цены',width=666, height=400)\n",
        "\n",
        "                      # Добавление точек на линию\n",
        "                      price_points = alt.Chart(df).mark_point(color='blue').encode(\n",
        "                          x='time:T',\n",
        "                          y='price:Q'\n",
        "                      )\n",
        "\n",
        "                      # Добавление текста над точками\n",
        "                      price_text = alt.Chart(df).mark_text(align='left', dx=5, dy=-5).encode(\n",
        "                          x='time:T',\n",
        "                          y='price:Q',\n",
        "                          text='price:Q'\n",
        "                      )\n",
        "\n",
        "                      # Объединение всех частей графика\n",
        "                      final_chart = price_line + price_points + price_text\n",
        "\n",
        "                      pred_price_line = alt.Chart(df).mark_line(color='red').encode(\n",
        "                            x=alt.X('next_time:T', axis=alt.Axis(format='%M', title='Минуты')),\n",
        "                            y=alt.Y('pred_price:Q', scale=alt.Scale(domain=[y_min_pred, y_max_pred]))\n",
        "                      ).properties(title='График изменения цены предсказания',width=666,height=400)\n",
        "\n",
        "                      # Добавление точек на линию\n",
        "                      pred_price_points = alt.Chart(df).mark_point(color='red').encode(\n",
        "                          x='next_time:T',\n",
        "                          y='pred_price:Q'\n",
        "                      )\n",
        "\n",
        "                      # Добавление текста над точками\n",
        "                      pred_price_text = alt.Chart(df).mark_text(align='left', dx=5, dy=-5).encode(\n",
        "                          x='next_time:T',\n",
        "                          y='pred_price:Q',\n",
        "                          text='pred_price:Q'\n",
        "                      )\n",
        "\n",
        "                      # Объединение всех частей графика\n",
        "                      pred_final_chart = pred_price_line + pred_price_points + pred_price_text\n",
        "\n",
        "                      # Отображение графика с центрированием\n",
        "\n",
        "\n",
        "                      chart1.altair_chart(pred_final_chart)\n",
        "                      # Задержка в 1 секунду\n",
        "                      await asyncio.sleep(1)\n",
        "                      chart2.altair_chart(final_chart)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                  except Exception as e:\n",
        "                      st.error(f\"Ошибка при получении котировок: {e}\")\n",
        "\n",
        "                  await asyncio.sleep(interval)\n",
        "\n",
        "      # Запуск асинхронной функции\n",
        "      interval = 60  # Интервал в секундах\n",
        "      asyncio.run(get_quotes_periodically(url, interval))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WALpP3dk_vL6",
        "outputId": "573e74a6-9c43-4c53-9985-11465c751462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ssh: connect to host serveo.net port 22: Connection refused\r\n"
          ]
        }
      ],
      "source": [
        "!streamlit run main.py --server.address=localhost >/content/logs.txt & ssh -o \"StrictHostKeyChecking no\" -R 80:localhost:8501 serveo.net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SLv5Ho5imMsT",
        "outputId": "29f2baf1-0bdf-49d8-a591-eaeaff1886e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Permanently added 'localhost.run' (RSA) to the list of known hosts.\r\n",
            "\n",
            "===============================================================================\n",
            "Welcome to localhost.run!\n",
            "\n",
            "Follow your favourite reverse tunnel at [https://twitter.com/localhost_run].\n",
            "\n",
            "To set up and manage custom domains go to https://admin.localhost.run/\n",
            "\n",
            "More details on custom domains (and how to enable subdomains of your custom\n",
            "domain) at https://localhost.run/docs/custom-domains\n",
            "\n",
            "If you get a permission denied error check the faq for how to connect with a key or\n",
            "create a free tunnel without a key at [http://localhost:3000/docs/faq#generating-an-ssh-key].\n",
            "\n",
            "To explore using localhost.run visit the documentation site:\n",
            "https://localhost.run/docs/\n",
            "\n",
            "===============================================================================\n",
            "\n",
            "** your connection id is 3519b7ca-145f-47fb-9cc5-e3e85d2cb03a, please mention it if you send me a message about an issue. **\n",
            "\n",
            "authenticated as anonymous user\r\r\n",
            "********************************************************************************\r\n",
            "Free plans are temporarily disabled. Please check back in a few days.\r\n",
            "\r\n",
            "\"Why?\" you ask.\r\n",
            "\r\n",
            "Over the past few days there has been an immense spike in free plan usage,\r\n",
            "and along with this bills suddently increased to 15 times their original amounts.\r\n",
            "Unfortunately this simply isn't an expenditure rate that the service can sustain,\r\n",
            "and better abuse prevention is needed before re-enabling the free plans.\r\n",
            "Once the root cause is determined and abuse prevention is in place free plans will\r\n",
            "be immediately re-enabled.\r\n",
            "\r\n",
            "I am deeply sorry for temporarily closing the door on free plans. if there were\r\n",
            "an alternative I would take it, but a short pause is needed to investigate.\r\n",
            "\r\n",
            "Please note: subscriptions are operating as normal, as accounting required to\r\n",
            "run them makes abuse prevention significantly easier for them and so they already\r\n",
            "have the required proteciton.\r\n",
            "********************************************************************************\r\r\n"
          ]
        }
      ],
      "source": [
        "!streamlit run main.py --server.address=localhost >/content/logs.txt & ssh -o \"StrictHostKeyChecking no\" -R 80:localhost:8501 nokey@localhost.run"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}